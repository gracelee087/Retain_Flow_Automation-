import pandas as pd
import streamlit as st
import pickle
from sqlalchemy import create_engine, MetaData, text
from sqlalchemy.dialects.postgresql import insert
import numpy as np
import streamlit as st
import os


# íƒ­ ìƒì„±
tab1, tab2, tab3, tab4, tab5= st.tabs(["Problem", "EDA", "Modeling/Evaluation", "Application", "Outcome"])



with tab1:
    st.header("Problem - ê¸°ë³¸ ì •ë³´")
    st.write("ì—¬ê¸°ì— ë‹¤ë¥¸ ê¸°ëŠ¥ì„ ë„£ì„ ìˆ˜ ìˆì–´ìš”")

with tab2:
    st.header("EDA - íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ê²°ê³¼")

    eda_path = r"C:\Users\honor\spicedAcademy\Capstone_Final_Project\Retain_Flow_Automation-\notebook\notebook\eda_insight"

    if os.path.exists(eda_path):
        img_files = [f for f in os.listdir(eda_path) if f.endswith((".png", ".jpg", ".jpeg"))]

        if img_files:
            for img in img_files:
                st.image(
                    os.path.join(eda_path, img),
                    caption=img,
                    use_container_width=True  # âœ… ë³€ê²½ë¨
                )
        else:
            st.warning("âš ï¸ EDA ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error("âŒ EDA ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")



with tab3:
    st.header("Modeling/Evaluation - ëª¨ë¸ ê²°ê³¼ í™•ì¸")
    st.write("ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼, í”¼ì²˜ ì¤‘ìš”ë„ ë“±")
    
    st.header("ğŸ§ª ëª¨ë¸ ì„±ëŠ¥ í™•ì¸")

    modeling_path = r"C:\Users\honor\spicedAcademy\Capstone_Final_Project\Retain_Flow_Automation-\notebook\notebook\modeling_insight"

    if os.path.exists(modeling_path):
        img_files = [f for f in os.listdir(modeling_path) if f.endswith((".png", ".jpg", ".jpeg"))]

        if img_files:
            for img in sorted(img_files):  # ì •ë ¬í•´ì„œ ìˆœì„œëŒ€ë¡œ ë³´ì—¬ì£¼ê¸°
                st.image(
                    os.path.join(modeling_path, img),
                    caption=img,
                    width=800 # âœ… ì›í•˜ëŠ” í¬ê¸° (px ë‹¨ìœ„)
                )
        else:
            st.warning("âš ï¸ ëª¨ë¸ ì„±ëŠ¥ ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error("âŒ ëª¨ë¸ë§ ê²°ê³¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

    # ---------------------------
    # Churn ëª¨ë¸ê³¼ Revenue ëª¨ë¸ êµ¬ë¶„ì„ 
    # ---------------------------
    st.divider()  # ìµœì‹  Streamlit
    # st.markdown("---")  # í˜¹ì€ ì´ ë°©ì‹ë„ ê°€ëŠ¥

    st.header("ğŸ’° Revenue ëª¨ë¸ ì„±ëŠ¥ ì‹œê°í™”")

    revenue_path = r"C:\Users\honor\spicedAcademy\Capstone_Final_Project\Retain_Flow_Automation-\notebook\revenue_insight"

    if os.path.exists(revenue_path):
        img_files = [f for f in os.listdir(revenue_path) if f.endswith(".png")]
        if img_files:
            for img in sorted(img_files):
                st.image(
                    os.path.join(revenue_path, img),
                    caption=img,
                    width=800
                )
        else:
            st.warning("âš ï¸ Revenue ëª¨ë¸ ì‹œê°í™” ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.error("âŒ Revenue ê²°ê³¼ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")







with tab4:
    st.header("Application - ê³ ê° ì´íƒˆ + ë§¤ì¶œ ì˜ˆì¸¡ (Supabase ì—°ë™)")

    # ---------------------------
    # 1. ëª¨ë¸ ë¡œë“œ
    # ---------------------------
    with open("notebook/pipeline_customer_churn_model.pkl", "rb") as f:
        bundle = pickle.load(f)

    model = bundle["model"]
    scaler = bundle["scaler"]
    kmeans = bundle["kmeans"]

    with open("notebook/pipeline_customer_revenue_model.pkl", "rb") as f:
        revenue_bundle = pickle.load(f)

    base_model = revenue_bundle["baseline_model"]
    residual_model = revenue_bundle["residual_model"]

    # ---------------------------
    # 2. Postgres DB ì—°ê²°
    # ---------------------------
    engine = create_engine(
        "postgresql://postgres:Nwk5JYywxV3ATT8M@db.fjaxvaegmtbsyogavuzy.supabase.co:5432/postgres"
    )

    # ---------------------------
    # 3. ì„¸ê·¸ë¨¼íŠ¸ ë¼ë²¨ë§ í•¨ìˆ˜ & base_message ë§¤í•‘
    # ---------------------------
    def label_cluster(cluster):
        if cluster == 2:
            return "High Risk & High Value"
        elif cluster == 0:
            return "Low Risk & High Value"
        elif cluster == 1:
            return "Low Risk & Low Value"
        elif cluster == 3:
            return "Low Risk & Mid Value"
        else:
            return "Unknown"

    base_messages = {
        "High Risk & High Value": "í”„ë¦¬ë¯¸ì—„ ê³ ê° ì „ìš© í˜œíƒ ì•ˆë‚´",
        "Low Risk & High Value": "VIP ê³ ê°ë‹˜ê»˜ ë“œë¦¬ëŠ” ê°ì‚¬ ì¸ì‚¬",
        "Low Risk & Low Value": "ê³ ê°ë‹˜ì˜ ì†Œì¤‘í•œ ì˜ê²¬ì„ ë“£ê³  ì‹¶ìŠµë‹ˆë‹¤",
        "Low Risk & Mid Value": "í¸ì•ˆí•œ ì„œë¹„ìŠ¤ ì´ìš©ì„ ìœ„í•œ ë§ì¶¤ ì œì•ˆ",
        "Unknown": "ê¸°ë³¸ ì•ˆë‚´ ë©”ì‹œì§€"
    }


    # ---------------------------
    # 4. Streamlit UI
    # ---------------------------
    st.title("ğŸ“Š ê³ ê° ì´íƒˆ + ë§¤ì¶œ ì˜ˆì¸¡ (Supabase ì—°ë™)")

    uploaded_file = st.file_uploader("ê³ ê° CSV ì—…ë¡œë“œ", type="csv")

    if uploaded_file:
        df = pd.read_csv(uploaded_file)

        # (1) ê³ ê° ì´íƒˆ í™•ë¥  ì˜ˆì¸¡
        df["churn_prob"] = model.predict_proba(df)[:, 1]

        # (2) ë§¤ì¶œ ì˜ˆì¸¡ (Baseline + Residual)
        X_base = df[["tenure", "MonthlyCharges"]]
        X_res = df[["PaymentMethod", "PaperlessBilling", "Dependents",
                    "OnlineBackup", "InternetService", "StreamingTV", "OnlineSecurity"]]

        baseline_pred = base_model.predict(X_base)
        residual_pred = residual_model.predict(X_res)
        df["predicted_revenue"] = np.clip(baseline_pred + residual_pred, a_min=0, a_max=None)

        # (3) ğŸ“Œ 12ê°œì›” ê¸°ì¤€ ì§€í‘œ
        df["revenue_12m"] = df["MonthlyCharges"] * 12
        df["expected_loss_12m"] = df["revenue_12m"] * df["churn_prob"]

        # (4) í´ëŸ¬ìŠ¤í„°ë§
        cluster_input = pd.DataFrame({
            "ChurnProbability": df["churn_prob"],
            "MonthlyCharges": df["MonthlyCharges"]
        })
        df["Cluster"] = kmeans.predict(scaler.transform(cluster_input))
        df["cluster_label"] = df["Cluster"].apply(label_cluster)

        # (5) base_message ìƒì„±
        df["base_message"] = df["cluster_label"].map(base_messages)

        # (6) ì»¬ëŸ¼ëª… DB í…Œì´ë¸”ê³¼ ë§ì¶”ê¸°
        df = df.rename(columns={
            "customerID": "customer_id",
            "Email": "email"
        })

        # ---------------------------
        # 7. Supabase DB ì €ì¥ (ì „ì²´ ê³ ê° â†’ predictions í…Œì´ë¸”)
        # ---------------------------
        metadata = MetaData()
        metadata.reflect(bind=engine)
        predictions_table = metadata.tables["predictions"]

        with engine.begin() as conn:
            for _, row in df.iterrows():
                stmt = insert(predictions_table).values(
                    customer_id=row["customer_id"],
                    email=row["email"],
                    churn_prob=row["churn_prob"],
                    cluster_label=row["cluster_label"],
                    base_message=row["base_message"],
                    predicted_revenue=row["predicted_revenue"],
                    revenue_12m=row["revenue_12m"],
                    expected_loss_12m=row["expected_loss_12m"]
                )
                stmt = stmt.on_conflict_do_update(
                    index_elements=["customer_id"],
                    set_={
                        "email": row["email"],
                        "churn_prob": row["churn_prob"],
                        "cluster_label": row["cluster_label"],
                        "base_message": row["base_message"],
                        "predicted_revenue": row["predicted_revenue"],
                        "revenue_12m": row["revenue_12m"],
                        "expected_loss_12m": row["expected_loss_12m"]
                    }
                )
                conn.execute(stmt)

        # ---------------------------
        # 8. Top 10 ê³ ê° ì €ì¥ (â†’ top_risk_customers í…Œì´ë¸”)
        # ---------------------------
        top10 = df.sort_values("expected_loss_12m", ascending=False).head(10)

        top_table = metadata.tables["top_risk_customers"]

        with engine.begin() as conn:
            # ê¸°ì¡´ ë°ì´í„° ì§€ìš°ê³  ìƒˆë¡œ ì €ì¥ (ë®ì–´ì“°ê¸° ë°©ì‹)
            conn.execute(text("TRUNCATE TABLE top_risk_customers;"))

            for _, row in top10.iterrows():
                stmt = insert(top_table).values(
                    customer_id=row["customer_id"],
                    email=row["email"],
                    churn_prob=row["churn_prob"],
                    cluster_label=row["cluster_label"],
                    base_message=row["base_message"],
                    predicted_revenue=row["predicted_revenue"],
                    revenue_12m=row["revenue_12m"],
                    expected_loss_12m=row["expected_loss_12m"]
                )
                conn.execute(stmt)

        # ---------------------------
        # 9. Streamlit ì¶œë ¥
        # ---------------------------
        st.subheader("ì˜ˆì¸¡ ë° ì„¸ê·¸ë¨¼íŠ¸ ê²°ê³¼")
        st.dataframe(df[["customer_id", "email", "churn_prob",
                        "cluster_label", "base_message",
                        "predicted_revenue",
                        "revenue_12m", "expected_loss_12m"]])

        st.subheader("Top 10 Revenue at Risk ê³ ê° (12M ê¸°ì¤€)")
        st.dataframe(top10)

        st.success("âœ… Supabase DB ì—…ë°ì´íŠ¸ ì™„ë£Œ! (ì „ì²´ predictions + Top 10 ì €ì¥)")




with tab5:
    st.header("Outcome - ê²°ë¡ (+product) ë° í–¥í›„ ê³¼ì œ")
    st.write("ì—¬ê¸°ì— ë‹¤ë¥¸ ê¸°ëŠ¥ì„ ë„£ì„ ìˆ˜ ìˆì–´ìš”")



















