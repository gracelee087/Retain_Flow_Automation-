{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\honor\\AppData\\Local\\Temp\\ipykernel_3572\\964693702.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[\"Churn\"] = df[\"Churn\"].replace({\"Yes\": 1, \"No\": 0})\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "최적 파라미터: {'clf__max_depth': 10, 'clf__max_features': 'log2', 'clf__min_samples_leaf': 2, 'clf__min_samples_split': 2, 'clf__n_estimators': 200}\n",
            "최고 Recall: 0.6240802675585285\n",
            "✅ 모델 + KMeans + Scaler 저장 완료\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cloudpickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 1. 데이터 불러오기\n",
        "# ---------------------------\n",
        "df = pd.read_csv(\"customer_Info copy.csv\")\n",
        "df = df.drop(columns=[\"customerID\"])\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\").fillna(0)\n",
        "df[\"Churn\"] = df[\"Churn\"].replace({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "X = df.drop(columns=[\"Churn\"])\n",
        "y = df[\"Churn\"]\n",
        "\n",
        "numeric_features = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
        "categorical_features = [col for col in X.columns if col not in numeric_features]\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 2. 전처리 + 모델 파이프라인\n",
        "# ---------------------------\n",
        "def clean_numeric(X):\n",
        "    X = X.copy()\n",
        "    for col in [\"TotalCharges\", \"MonthlyCharges\", \"tenure\"]:\n",
        "        X[col] = pd.to_numeric(X[col], errors=\"coerce\").fillna(0)\n",
        "    return X\n",
        "\n",
        "numeric_cleaner = FunctionTransformer(clean_numeric)\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", \"passthrough\", numeric_features),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"cleaner\", numeric_cleaner),\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"smote\", SMOTE(random_state=42)),\n",
        "    (\"clf\", RandomForestClassifier(random_state=42, class_weight=\"balanced\"))\n",
        "])\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 3. 하이퍼파라미터 튜닝\n",
        "# ---------------------------\n",
        "param_grid = {\n",
        "    \"clf__n_estimators\": [200, 500],\n",
        "    \"clf__max_depth\": [10, 20, None],\n",
        "    \"clf__min_samples_split\": [2, 5],\n",
        "    \"clf__min_samples_leaf\": [1, 2],\n",
        "    \"clf__max_features\": [\"sqrt\", \"log2\"]\n",
        "}\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"recall\",\n",
        "    cv=skf,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 4. 학습 & 보정\n",
        "# ---------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"최적 파라미터:\", grid_search.best_params_)\n",
        "print(\"최고 Recall:\", grid_search.best_score_)\n",
        "\n",
        "best_pipeline = grid_search.best_estimator_\n",
        "\n",
        "calibrated_rfc = CalibratedClassifierCV(\n",
        "    estimator=best_pipeline,\n",
        "    method=\"sigmoid\",\n",
        "    cv=5\n",
        ")\n",
        "calibrated_rfc.fit(X_train, y_train)\n",
        "\n",
        "# ---------------------------\n",
        "# 5. 추가 세그먼트용 KMeans\n",
        "# ---------------------------\n",
        "y_prob = calibrated_rfc.predict_proba(X)[:, 1]\n",
        "X_cluster = pd.DataFrame({\n",
        "    \"ChurnProbability\": y_prob,\n",
        "    \"MonthlyCharges\": X[\"MonthlyCharges\"]\n",
        "})\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_cluster)\n",
        "\n",
        "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
        "kmeans.fit(X_scaled)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# 6. 저장 (모델 + 스케일러 + 클러스터러)\n",
        "# ---------------------------\n",
        "bundle = {\n",
        "    \"model\": calibrated_rfc,\n",
        "    \"scaler\": scaler,\n",
        "    \"kmeans\": kmeans\n",
        "}\n",
        "\n",
        "with open(\"pipeline_customer_churn_model.pkl\", \"wb\") as f:\n",
        "    cloudpickle.dump(bundle, f)\n",
        "\n",
        "print(\"✅ 모델 + KMeans + Scaler 저장 완료\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
